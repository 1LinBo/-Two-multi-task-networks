{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the second multi-task network\n",
    "\n",
    "In this notebook we introduce the use of the second multi-task network through an example dataset (TCGA-BRCA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import related packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchtuples as tt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from pycox.models.utils import pad_col\n",
    "from pycox.preprocessing.label_transforms import LabTransDiscreteTime\n",
    "from pycox import models\n",
    "from typing import Tuple\n",
    "from torch import Tensor\n",
    "from pycox.models import utils\n",
    "from torchtuples import TupleTree\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/')\n",
    "from eval import EvalSurv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some seeds to make this reproducable\n",
    "np.random.seed(123456)\n",
    "_ = torch.manual_seed(123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MGST2</th>\n",
       "      <th>SGK1</th>\n",
       "      <th>PARD6B</th>\n",
       "      <th>DRD3</th>\n",
       "      <th>GNG10</th>\n",
       "      <th>TAAR2</th>\n",
       "      <th>FZR1</th>\n",
       "      <th>CNTFR</th>\n",
       "      <th>E2F5</th>\n",
       "      <th>IFNA1</th>\n",
       "      <th>...</th>\n",
       "      <th>SMC1B</th>\n",
       "      <th>IL1B</th>\n",
       "      <th>L2HGDH</th>\n",
       "      <th>PPARGC1A</th>\n",
       "      <th>VCAM1</th>\n",
       "      <th>MADCAM1</th>\n",
       "      <th>event2</th>\n",
       "      <th>T2</th>\n",
       "      <th>event1</th>\n",
       "      <th>T1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.64</td>\n",
       "      <td>8.29</td>\n",
       "      <td>8.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.76</td>\n",
       "      <td>2.36</td>\n",
       "      <td>6.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.76</td>\n",
       "      <td>5.43</td>\n",
       "      <td>8.17</td>\n",
       "      <td>2.04</td>\n",
       "      <td>8.43</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0</td>\n",
       "      <td>4047</td>\n",
       "      <td>1</td>\n",
       "      <td>1808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.36</td>\n",
       "      <td>9.24</td>\n",
       "      <td>8.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.87</td>\n",
       "      <td>4.16</td>\n",
       "      <td>6.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.42</td>\n",
       "      <td>4.64</td>\n",
       "      <td>8.19</td>\n",
       "      <td>2.09</td>\n",
       "      <td>9.61</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0</td>\n",
       "      <td>4005</td>\n",
       "      <td>0</td>\n",
       "      <td>4005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.89</td>\n",
       "      <td>9.58</td>\n",
       "      <td>7.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.74</td>\n",
       "      <td>5.18</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>3.20</td>\n",
       "      <td>8.03</td>\n",
       "      <td>2.47</td>\n",
       "      <td>9.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1474</td>\n",
       "      <td>0</td>\n",
       "      <td>1474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.59</td>\n",
       "      <td>9.82</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.36</td>\n",
       "      <td>5.16</td>\n",
       "      <td>7.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.16</td>\n",
       "      <td>7.06</td>\n",
       "      <td>7.32</td>\n",
       "      <td>6.28</td>\n",
       "      <td>9.78</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0</td>\n",
       "      <td>1448</td>\n",
       "      <td>0</td>\n",
       "      <td>1448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.07</td>\n",
       "      <td>10.40</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.76</td>\n",
       "      <td>4.75</td>\n",
       "      <td>8.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.99</td>\n",
       "      <td>5.17</td>\n",
       "      <td>8.04</td>\n",
       "      <td>4.98</td>\n",
       "      <td>7.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>348</td>\n",
       "      <td>0</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4917 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MGST2   SGK1  PARD6B  DRD3  GNG10  TAAR2   FZR1  CNTFR  E2F5  IFNA1  ...  \\\n",
       "0   8.64   8.29    8.74   0.0   8.01    0.0  10.76   2.36  6.99    0.0  ...   \n",
       "1   9.36   9.24    8.23   0.0   8.57    0.0  10.87   4.16  6.45    0.0  ...   \n",
       "2   9.89   9.58    7.82   0.0   9.13    0.0  10.74   5.18  7.50    0.0  ...   \n",
       "3   9.59   9.82    8.05   0.0   8.43    0.0  10.36   5.16  7.17    0.0  ...   \n",
       "4   8.07  10.40    8.43   0.0   8.62    0.0   9.76   4.75  8.12    0.0  ...   \n",
       "\n",
       "   SMC1B  IL1B  L2HGDH  PPARGC1A  VCAM1  MADCAM1  event2    T2  event1    T1  \n",
       "0   0.76  5.43    8.17      2.04   8.43     3.37       0  4047       1  1808  \n",
       "1   7.42  4.64    8.19      2.09   9.61     3.36       0  4005       0  4005  \n",
       "2   0.93  3.20    8.03      2.47   9.01     0.00       0  1474       0  1474  \n",
       "3   1.16  7.06    7.32      6.28   9.78     1.16       0  1448       0  1448  \n",
       "4   1.99  5.17    8.04      4.98   7.48     0.00       0   348       0   348  \n",
       "\n",
       "[5 rows x 4917 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "file1 = 'BRCA1.txt'\n",
    "file2 = 'BRCA2.txt'\n",
    "\n",
    "with open(file1, 'r', encoding='utf-8') as f1:\n",
    "    lines1 = f1.readlines()\n",
    "\n",
    "with open(file2, 'r', encoding='utf-8') as f2:\n",
    "    lines2 = f2.readlines()\n",
    "\n",
    "combined_lines = lines1 + lines2\n",
    "\n",
    "output_file = 'BRCA.txt'\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    outfile.writelines(combined_lines)\n",
    "    \n",
    "file_path = 'BRCA.txt'\n",
    "\n",
    "df = pd.read_csv(file_path, sep='\\t', header=0)\n",
    "\n",
    "# Leaving only the genetic data associated with the 186KEGG pathway\n",
    "def parse_kegg_file(file_path):\n",
    "    kegg_data = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('KEGG'):\n",
    "                parts = line.strip().split('\\t')\n",
    "                pathway_name = parts[0]\n",
    "                genes = parts[2:] if len(parts) > 2 else []\n",
    "                kegg_data[pathway_name] = genes\n",
    "    return kegg_data\n",
    "\n",
    "file_path = 'kegg_legacy.txt'\n",
    "kegg_pathways = parse_kegg_file(file_path)\n",
    "\n",
    "all_genes = set()\n",
    "\n",
    "for genes in kegg_pathways.values():\n",
    "    all_genes.update(genes)\n",
    "\n",
    "genes_columns = [gene for gene in all_genes if gene in df.columns]\n",
    "\n",
    "filtered_df_train = df[genes_columns]\n",
    "\n",
    "filtered_kegg_pathways = {}\n",
    "for pathway, genes in kegg_pathways.items():\n",
    "    filtered_genes = [gene for gene in genes if gene in genes_columns]\n",
    "    filtered_kegg_pathways[pathway] = filtered_genes\n",
    "\n",
    "concatenated_df = pd.concat([filtered_df_train, df.iloc[:,-4:]], axis=1)\n",
    "\n",
    "df_train = concatenated_df\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse connection layer mask matrix\n",
    "num_pathways = len(filtered_kegg_pathways)\n",
    "num_genes = len(genes_columns)\n",
    "\n",
    "mask = torch.zeros(num_pathways, num_genes, dtype=torch.bool)\n",
    "\n",
    "gene_to_index = {gene: idx for idx, gene in enumerate(genes_columns)}\n",
    "\n",
    "for pathway_idx, (pathway, genes) in enumerate(filtered_kegg_pathways.items()):\n",
    "    for gene in genes:\n",
    "        if gene in gene_to_index:\n",
    "            gene_idx = gene_to_index[gene]\n",
    "            mask[pathway_idx, gene_idx] = 1  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MGST2',\n",
       " 'SGK1',\n",
       " 'PARD6B',\n",
       " 'DRD3',\n",
       " 'GNG10',\n",
       " 'TAAR2',\n",
       " 'FZR1',\n",
       " 'CNTFR',\n",
       " 'E2F5',\n",
       " 'IFNA1',\n",
       " 'TAF4B',\n",
       " 'DET1',\n",
       " 'MYD88',\n",
       " 'MAP3K11',\n",
       " 'ABCD4',\n",
       " 'NOG',\n",
       " 'CRLS1',\n",
       " 'CAMK2A',\n",
       " 'TTK',\n",
       " 'IL21R',\n",
       " 'CHAT',\n",
       " 'CBLC',\n",
       " 'SARDH',\n",
       " 'CHRM2',\n",
       " 'PDHB',\n",
       " 'RPL39',\n",
       " 'ICAM2',\n",
       " 'HMGCS2',\n",
       " 'MAGI1',\n",
       " 'COL2A1',\n",
       " 'STAT4',\n",
       " 'DHRS3',\n",
       " 'TFDP1',\n",
       " 'UGCG',\n",
       " 'OR13C8',\n",
       " 'CYP11B1',\n",
       " 'BUB3',\n",
       " 'CASP5',\n",
       " 'GABRA6',\n",
       " 'OR5AS1',\n",
       " 'RPS6KA3',\n",
       " 'RAB11FIP2',\n",
       " 'ACOX1',\n",
       " 'E2F1',\n",
       " 'MYH2',\n",
       " 'OXCT2',\n",
       " 'CDKN2D',\n",
       " 'CADM3',\n",
       " 'GABRG3',\n",
       " 'TAS2R5',\n",
       " 'CACNB3',\n",
       " 'PGK1',\n",
       " 'DDC',\n",
       " 'OR52K2',\n",
       " 'CYP2A7',\n",
       " 'ACVR1C',\n",
       " 'DSC2',\n",
       " 'CHIT1',\n",
       " 'MOS',\n",
       " 'SRD5A1',\n",
       " 'GAMT',\n",
       " 'MRAS',\n",
       " 'LRAT',\n",
       " 'NDUFB7',\n",
       " 'ATP6V0A2',\n",
       " 'SPCS1',\n",
       " 'AACS',\n",
       " 'ALS2',\n",
       " 'MFNG',\n",
       " 'OR8B12',\n",
       " 'CCNB2',\n",
       " 'MAP4K1',\n",
       " 'JAG1',\n",
       " 'SLC18A2',\n",
       " 'OR6C65',\n",
       " 'ATP6V0D2',\n",
       " 'DHRS4L2',\n",
       " 'OR8H3',\n",
       " 'DHX8',\n",
       " 'DAPK1',\n",
       " 'GTF2B',\n",
       " 'SNW1',\n",
       " 'CCND1',\n",
       " 'ELOVL6',\n",
       " 'GNAO1',\n",
       " 'PRPF19',\n",
       " 'TNFRSF10C',\n",
       " 'DUSP3',\n",
       " 'VWF',\n",
       " 'GPX1',\n",
       " 'TUBA1C',\n",
       " 'EI24',\n",
       " 'AP3M1',\n",
       " 'NCR3',\n",
       " 'GOSR2',\n",
       " 'TNR',\n",
       " 'P2RX4',\n",
       " 'IGF2R',\n",
       " 'NR1H3',\n",
       " 'FSHB',\n",
       " 'GABRR2',\n",
       " 'PLA2G4D',\n",
       " 'SF3B2',\n",
       " 'XRCC4',\n",
       " 'VAMP2',\n",
       " 'LYPLA2',\n",
       " 'UGT1A8',\n",
       " 'PRPF4',\n",
       " 'FZD4',\n",
       " 'FMO2',\n",
       " 'LEP',\n",
       " 'WASL',\n",
       " 'TAB2',\n",
       " 'OR5M8',\n",
       " 'MSH3',\n",
       " 'ROBO1',\n",
       " 'FOS',\n",
       " 'KITLG',\n",
       " 'ALDH4A1',\n",
       " 'DNAH2',\n",
       " 'CACNB2',\n",
       " 'DGAT1',\n",
       " 'RPL14',\n",
       " 'RAMP2',\n",
       " 'OR52B4',\n",
       " 'PTDSS1',\n",
       " 'UBE4A',\n",
       " 'HEXB',\n",
       " 'P4HA1',\n",
       " 'DTYMK',\n",
       " 'RAD51C',\n",
       " 'BCR',\n",
       " 'B3GNT3',\n",
       " 'COX7A2L',\n",
       " 'OR51A7',\n",
       " 'ADO',\n",
       " 'RHOQ',\n",
       " 'IBSP',\n",
       " 'C2',\n",
       " 'TBPL2',\n",
       " 'NRAS',\n",
       " 'PTK2',\n",
       " 'CXCR2',\n",
       " 'PRDX6',\n",
       " 'INHBB',\n",
       " 'GCLM',\n",
       " 'BCAT1',\n",
       " 'NF1',\n",
       " 'SRP72',\n",
       " 'RGS3',\n",
       " 'GSTA5',\n",
       " 'CDO1',\n",
       " 'CCR10',\n",
       " 'CSNK1D',\n",
       " 'PIAS1',\n",
       " 'UBE2D3',\n",
       " 'DGKE',\n",
       " 'IKBKG',\n",
       " 'GAL3ST1',\n",
       " 'UGT1A5',\n",
       " 'UBA2',\n",
       " 'PIK3C2G',\n",
       " 'OR2J2',\n",
       " 'UBE2H',\n",
       " 'BHLHE40',\n",
       " 'NRXN1',\n",
       " 'KDELR2',\n",
       " 'GTF2H1',\n",
       " 'PIP5K1A',\n",
       " 'VAMP8',\n",
       " 'SNRPD1',\n",
       " 'OR4F4',\n",
       " 'PRKCE',\n",
       " 'CTNND1',\n",
       " 'HNRNPA1L2',\n",
       " 'WNT2',\n",
       " 'PMM2',\n",
       " 'PRPH2',\n",
       " 'EIF4A3',\n",
       " 'TRHR',\n",
       " 'CRK',\n",
       " 'CARD8',\n",
       " 'FZD5',\n",
       " 'PKP2',\n",
       " 'OR2T1',\n",
       " 'AREG',\n",
       " 'CARD9',\n",
       " 'DPYS',\n",
       " 'PLD2',\n",
       " 'HTR1E',\n",
       " 'CD28',\n",
       " 'EPB41L1',\n",
       " 'EDN1',\n",
       " 'MAP4K3',\n",
       " 'GTF2F2',\n",
       " 'GART',\n",
       " 'STT3B',\n",
       " 'RFC4',\n",
       " 'SRC',\n",
       " 'COX5B',\n",
       " 'TACR3',\n",
       " 'VTN',\n",
       " 'TAS2R9',\n",
       " 'ITGA8',\n",
       " 'SGCG',\n",
       " 'PIK3C2A',\n",
       " 'DBI',\n",
       " 'RPL3',\n",
       " 'GTF2F1',\n",
       " 'CIR1',\n",
       " 'IL2RB',\n",
       " 'GCAT',\n",
       " 'CARD6',\n",
       " 'PSMD2',\n",
       " 'SEMA3D',\n",
       " 'PNLIP',\n",
       " 'NPR2',\n",
       " 'DCP1B',\n",
       " 'DAO',\n",
       " 'PPM1D',\n",
       " 'CCL20',\n",
       " 'PERP',\n",
       " 'GLUD1',\n",
       " 'GOT2',\n",
       " 'M6PR',\n",
       " 'CD5',\n",
       " 'PARK7',\n",
       " 'PIK3CD',\n",
       " 'GAA',\n",
       " 'MLST8',\n",
       " 'OR51G1',\n",
       " 'LPAR3',\n",
       " 'CD2',\n",
       " 'AQP3',\n",
       " 'ETS2',\n",
       " 'CCL1',\n",
       " 'ABCC2',\n",
       " 'RNASEH2B',\n",
       " 'POLR2J3',\n",
       " 'TAF5',\n",
       " 'OR2T8',\n",
       " 'MASP2',\n",
       " 'CUL2',\n",
       " 'ATP6V1E1',\n",
       " 'CSF2RB',\n",
       " 'KDELR3',\n",
       " 'GALNS',\n",
       " 'ENDOG',\n",
       " 'GAPDH',\n",
       " 'LDHD',\n",
       " 'NFASC',\n",
       " 'OR4A16',\n",
       " 'OR5T3',\n",
       " 'OR2L13',\n",
       " 'STMN1',\n",
       " 'WNT5B',\n",
       " 'DUSP4',\n",
       " 'ACTB',\n",
       " 'ACTG2',\n",
       " 'SEMA6C',\n",
       " 'CCR9',\n",
       " 'OR2B3',\n",
       " 'APC',\n",
       " 'CHMP4A',\n",
       " 'ECHS1',\n",
       " 'TAS2R14',\n",
       " 'PARVB',\n",
       " 'SH3KBP1',\n",
       " 'OR11L1',\n",
       " 'DHRS9',\n",
       " 'OR4N5',\n",
       " 'XAB2',\n",
       " 'THPO',\n",
       " 'BMP4',\n",
       " 'PDSS1',\n",
       " 'WNT10A',\n",
       " 'WNT11',\n",
       " 'PLXNB2',\n",
       " 'THBS2',\n",
       " 'CDC20',\n",
       " 'PRKDC',\n",
       " 'CAPN2',\n",
       " 'STX5',\n",
       " 'AQP1',\n",
       " 'PGAM4',\n",
       " 'OR4K2',\n",
       " 'CSF1',\n",
       " 'CHMP6',\n",
       " 'FBXO43',\n",
       " 'SSTR4',\n",
       " 'BNIP1',\n",
       " 'NFKB1',\n",
       " 'HES1',\n",
       " 'HTR1F',\n",
       " 'OR6C3',\n",
       " 'MYO10',\n",
       " 'ETNK2',\n",
       " 'RPA3',\n",
       " 'PIP4K2B',\n",
       " 'IL2RG',\n",
       " 'TNFRSF8',\n",
       " 'CYP1A2',\n",
       " 'UCKL1',\n",
       " 'LDHAL6A',\n",
       " 'TAS2R39',\n",
       " 'UGT2B10',\n",
       " 'EHMT1',\n",
       " 'NAGLU',\n",
       " 'EXOSC6',\n",
       " 'NLN',\n",
       " 'PRODH2',\n",
       " 'ATP2A3',\n",
       " 'OR56A5',\n",
       " 'EPHX2',\n",
       " 'EDC3',\n",
       " 'FDFT1',\n",
       " 'PLA2G2E',\n",
       " 'MTAP',\n",
       " 'FGF11',\n",
       " 'PGM2L1',\n",
       " 'OR51S1',\n",
       " 'EIF4G1',\n",
       " 'AP1M2',\n",
       " 'PPP2R5C',\n",
       " 'RAG2',\n",
       " 'TAF13',\n",
       " 'ACTN3',\n",
       " 'ARF6',\n",
       " 'DGAT2',\n",
       " 'MAGI2',\n",
       " 'MCHR2',\n",
       " 'XRCC6',\n",
       " 'CDC14B',\n",
       " 'RHEB',\n",
       " 'RBPJL',\n",
       " 'ALDH3B1',\n",
       " 'HEMK1',\n",
       " 'MYL6B',\n",
       " 'PIGN',\n",
       " 'PKMYT1',\n",
       " 'SSH2',\n",
       " 'TGFB1',\n",
       " 'COL6A3',\n",
       " 'TRA2A',\n",
       " 'CMPK1',\n",
       " 'MCM3',\n",
       " 'IKBKB',\n",
       " 'FLT3LG',\n",
       " 'PRPS1L1',\n",
       " 'EXOSC8',\n",
       " 'PLA2G1B',\n",
       " 'MTHFR',\n",
       " 'GALNT14',\n",
       " 'TCF7L1',\n",
       " 'SSX2IP',\n",
       " 'CCR4',\n",
       " 'COX7A1',\n",
       " 'PLAT',\n",
       " 'SOS2',\n",
       " 'ATP1A1',\n",
       " 'HNMT',\n",
       " 'COX15',\n",
       " 'GFPT2',\n",
       " 'OR5K1',\n",
       " 'FGF7',\n",
       " 'TRAF6',\n",
       " 'CCL16',\n",
       " 'CALML6',\n",
       " 'GSR',\n",
       " 'MAML3',\n",
       " 'PSME4',\n",
       " 'CD37',\n",
       " 'OR2H2',\n",
       " 'MBOAT2',\n",
       " 'TG',\n",
       " 'GABRA5',\n",
       " 'MYH7B',\n",
       " 'SRGAP2',\n",
       " 'RPL36AL',\n",
       " 'JAK3',\n",
       " 'HCLS1',\n",
       " 'SLC6A3',\n",
       " 'TLR1',\n",
       " 'SORD',\n",
       " 'SLC11A2',\n",
       " 'ERCC8',\n",
       " 'PTDSS2',\n",
       " 'UBE3C',\n",
       " 'NAE1',\n",
       " 'PEX10',\n",
       " 'GNG13',\n",
       " 'PLA2G2F',\n",
       " 'UGT2B7',\n",
       " 'OR1J2',\n",
       " 'OR51G2',\n",
       " 'CCL8',\n",
       " 'TRAF2',\n",
       " 'DUSP8',\n",
       " 'ITGA6',\n",
       " 'SGCD',\n",
       " 'SLC12A2',\n",
       " 'OR2T33',\n",
       " 'ST3GAL1',\n",
       " 'DCN',\n",
       " 'ABCG4',\n",
       " 'NODAL',\n",
       " 'CCL24',\n",
       " 'PI4KA',\n",
       " 'OR9I1',\n",
       " 'PTGER2',\n",
       " 'HTR4',\n",
       " 'GNG11',\n",
       " 'LPCAT2',\n",
       " 'RPL31',\n",
       " 'SEMA3C',\n",
       " 'ABCC9',\n",
       " 'HRH1',\n",
       " 'PRKCD',\n",
       " 'MYH1',\n",
       " 'RNF7',\n",
       " 'SRM',\n",
       " 'MAGOH',\n",
       " 'MLH1',\n",
       " 'NFATC3',\n",
       " 'IDH3A',\n",
       " 'CUL4A',\n",
       " 'PCCB',\n",
       " 'CYB5R1',\n",
       " 'TNFRSF10A',\n",
       " 'UBE2A',\n",
       " 'LPL',\n",
       " 'ACP1',\n",
       " 'OPRM1',\n",
       " 'EXOSC7',\n",
       " 'ALG12',\n",
       " 'KLRD1',\n",
       " 'ST8SIA5',\n",
       " 'OR6C6',\n",
       " 'SHMT1',\n",
       " 'TIAM2',\n",
       " 'TAS1R3',\n",
       " 'TSPO',\n",
       " 'FGF9',\n",
       " 'PANK3',\n",
       " 'ATP1A2',\n",
       " 'ACAA1',\n",
       " 'CXCL14',\n",
       " 'OR2K2',\n",
       " 'MAP3K3',\n",
       " 'P2RY11',\n",
       " 'OR14C36',\n",
       " 'MKNK1',\n",
       " 'SFRP1',\n",
       " 'EXT1',\n",
       " 'OR51E2',\n",
       " 'MLYCD',\n",
       " 'IL4',\n",
       " 'PTTG2',\n",
       " 'NRXN2',\n",
       " 'OR10G7',\n",
       " 'OR52N5',\n",
       " 'AIM2',\n",
       " 'PIP5K1B',\n",
       " 'ITGA2',\n",
       " 'CLDN23',\n",
       " 'TK1',\n",
       " 'SNRPC',\n",
       " 'SORBS1',\n",
       " 'VEGFB',\n",
       " 'FABP3',\n",
       " 'PAK1',\n",
       " 'FUT2',\n",
       " 'STAM2',\n",
       " 'C8A',\n",
       " 'CREB5',\n",
       " 'CCL25',\n",
       " 'ERBB4',\n",
       " 'SEMA6D',\n",
       " 'SNRPE',\n",
       " 'TYK2',\n",
       " 'XYLB',\n",
       " 'NDUFS5',\n",
       " 'OR5D13',\n",
       " 'PDE8B',\n",
       " 'THBD',\n",
       " 'HHIP',\n",
       " 'MPV17',\n",
       " 'PPP2CB',\n",
       " 'AXIN2',\n",
       " 'STX6',\n",
       " 'DHDDS',\n",
       " 'TP73',\n",
       " 'ABCA4',\n",
       " 'ULBP1',\n",
       " 'ENPP2',\n",
       " 'OR8H1',\n",
       " 'IFNK',\n",
       " 'CES2',\n",
       " 'POLE4',\n",
       " 'IRS1',\n",
       " 'GRIA1',\n",
       " 'GTF2H3',\n",
       " 'PEX6',\n",
       " 'CHRM5',\n",
       " 'VPS37A',\n",
       " 'ASAP1',\n",
       " 'EPX',\n",
       " 'OR12D2',\n",
       " 'PAPOLB',\n",
       " 'CXCL5',\n",
       " 'FASLG',\n",
       " 'AP1S1',\n",
       " 'CD7',\n",
       " 'LPCAT1',\n",
       " 'SP1',\n",
       " 'PRKAR1B',\n",
       " 'HARS2',\n",
       " 'RPL34',\n",
       " 'RFK',\n",
       " 'PIGK',\n",
       " 'VIPR1',\n",
       " 'CRNKL1',\n",
       " 'AMOTL1',\n",
       " 'CHKA',\n",
       " 'POLR2L',\n",
       " 'SLC27A4',\n",
       " 'GABRA4',\n",
       " 'REN',\n",
       " 'TAS2R3',\n",
       " 'CCL14',\n",
       " 'MAFA',\n",
       " 'EIF4G2',\n",
       " 'ATG4A',\n",
       " 'STAT2',\n",
       " 'SDC2',\n",
       " 'PSMA8',\n",
       " 'CCL22',\n",
       " 'SEC62',\n",
       " 'TBL1XR1',\n",
       " 'CASP3',\n",
       " 'CXCL2',\n",
       " 'OR2A4',\n",
       " 'TMSB4Y',\n",
       " 'DDOST',\n",
       " 'BAX',\n",
       " 'RPL13',\n",
       " 'ADA',\n",
       " 'OPLAH',\n",
       " 'GABARAP',\n",
       " 'MGAT1',\n",
       " 'DIS3',\n",
       " 'SMAD4',\n",
       " 'ADRB3',\n",
       " 'GRK6',\n",
       " 'CDH3',\n",
       " 'KMO',\n",
       " 'NEU2',\n",
       " 'FOXO1',\n",
       " 'AGPAT3',\n",
       " 'COL1A2',\n",
       " 'IL2RA',\n",
       " 'CACNG5',\n",
       " 'STAMBP',\n",
       " 'UBE2Z',\n",
       " 'RAD52',\n",
       " 'CPB2',\n",
       " 'HNF4A',\n",
       " 'EGR1',\n",
       " 'CTSE',\n",
       " 'CLTCL1',\n",
       " 'CTNNBL1',\n",
       " 'NME6',\n",
       " 'OR2A25',\n",
       " 'ENTPD2',\n",
       " 'DDX3X',\n",
       " 'CPEB1',\n",
       " 'GUCA1B',\n",
       " 'CDKN2A',\n",
       " 'GSTM3',\n",
       " 'RAB11FIP1',\n",
       " 'NSF',\n",
       " 'ACTC1',\n",
       " 'INPP5J',\n",
       " 'NEU3',\n",
       " 'TPH1',\n",
       " 'BMP2',\n",
       " 'B3GAT2',\n",
       " 'PGK2',\n",
       " 'PLA2G5',\n",
       " 'MNAT1',\n",
       " 'GSTP1',\n",
       " 'NMNAT2',\n",
       " 'OR5I1',\n",
       " 'CISH',\n",
       " 'CACNG8',\n",
       " 'DDIT4',\n",
       " 'TRAF3',\n",
       " 'ASMT',\n",
       " 'TPI1',\n",
       " 'NRG4',\n",
       " 'SEMA5A',\n",
       " 'PSMD11',\n",
       " 'GSTM1',\n",
       " 'SYNJ2',\n",
       " 'BET1',\n",
       " 'AARS2',\n",
       " 'ITPR3',\n",
       " 'ACSS1',\n",
       " 'FZD6',\n",
       " 'PEX3',\n",
       " 'SHC2',\n",
       " 'ACTA2',\n",
       " 'IGLL1',\n",
       " 'SRP19',\n",
       " 'CDKN1B',\n",
       " 'PARD6G',\n",
       " 'NSD1',\n",
       " 'ENPEP',\n",
       " 'ETS1',\n",
       " 'NDUFA4',\n",
       " 'PTGS1',\n",
       " 'SGCB',\n",
       " 'SEC61A2',\n",
       " 'SAT2',\n",
       " 'OR10A2',\n",
       " 'ARFGAP1',\n",
       " 'MPV17L',\n",
       " 'BMP8B',\n",
       " 'OR8K3',\n",
       " 'PRKAG2',\n",
       " 'KHK',\n",
       " 'P4HA3',\n",
       " 'CREB3L4',\n",
       " 'NTN3',\n",
       " 'IRAK1',\n",
       " 'GNRH2',\n",
       " 'TAS2R46',\n",
       " 'QDPR',\n",
       " 'PRKACA',\n",
       " 'CDC25C',\n",
       " 'ABCD2',\n",
       " 'MBD4',\n",
       " 'SDS',\n",
       " 'PRKACG',\n",
       " 'BAAT',\n",
       " 'TNXB',\n",
       " 'NUDT12',\n",
       " 'OR13C5',\n",
       " 'TNNC1',\n",
       " 'AKR1A1',\n",
       " 'VARS2',\n",
       " 'MAP3K2',\n",
       " 'OR2Z1',\n",
       " 'PRNP',\n",
       " 'NUDT5',\n",
       " 'BST1',\n",
       " 'CNOT6',\n",
       " 'NT5C2',\n",
       " 'OR52J3',\n",
       " 'PORCN',\n",
       " 'CAMK2G',\n",
       " 'RPE',\n",
       " 'CDC5L',\n",
       " 'AGAP1',\n",
       " 'SEMA4B',\n",
       " 'GRIA4',\n",
       " 'KEAP1',\n",
       " 'PPP3CC',\n",
       " 'FGF2',\n",
       " 'ETV6',\n",
       " 'EPB41L2',\n",
       " 'MAVS',\n",
       " 'MAS1',\n",
       " 'HSD17B1',\n",
       " 'MAPK8',\n",
       " 'OR8K5',\n",
       " 'C5AR1',\n",
       " 'OR2T4',\n",
       " 'ALPP',\n",
       " 'AGPAT1',\n",
       " 'PRKCA',\n",
       " 'PTPN7',\n",
       " 'PTTG1',\n",
       " 'GGT6',\n",
       " 'OR6N1',\n",
       " 'COL5A3',\n",
       " 'PLXNB3',\n",
       " 'MARCKSL1',\n",
       " 'TSC2',\n",
       " 'ICA1',\n",
       " 'DNM1L',\n",
       " 'PSMA1',\n",
       " 'CHKB',\n",
       " 'SIPA1',\n",
       " 'CCNH',\n",
       " 'ACSL3',\n",
       " 'SOAT2',\n",
       " 'LAMC1',\n",
       " 'CANT1',\n",
       " 'LIPF',\n",
       " 'NEU4',\n",
       " 'CLDN17',\n",
       " 'IL18RAP',\n",
       " 'GPT',\n",
       " 'IARS2',\n",
       " 'XPA',\n",
       " 'OR52H1',\n",
       " 'TAS2R50',\n",
       " 'PDGFD',\n",
       " 'CRH',\n",
       " 'GLP1R',\n",
       " 'BDH2',\n",
       " 'GADD45G',\n",
       " 'ABCA2',\n",
       " 'OR52N2',\n",
       " 'AQR',\n",
       " 'SLC25A31',\n",
       " 'CCNB1',\n",
       " 'RFNG',\n",
       " 'UBA3',\n",
       " 'ST3GAL3',\n",
       " 'IL6R',\n",
       " 'PAX6',\n",
       " 'OR51D1',\n",
       " 'SPTAN1',\n",
       " 'MUC2',\n",
       " 'CSF3R',\n",
       " 'OR4M1',\n",
       " 'HSPG2',\n",
       " 'IPPK',\n",
       " 'SART1',\n",
       " 'ARPC4',\n",
       " 'COL4A2',\n",
       " 'NTF3',\n",
       " 'OR6B3',\n",
       " 'C1GALT1',\n",
       " 'GALNT6',\n",
       " 'EXTL2',\n",
       " 'INPP5D',\n",
       " 'CTSC',\n",
       " 'POLR2H',\n",
       " 'MPST',\n",
       " 'JUP',\n",
       " 'NPY',\n",
       " 'ALDH1L1',\n",
       " 'PIK3CG',\n",
       " 'NOD2',\n",
       " 'KCNB1',\n",
       " 'SPIRE1',\n",
       " 'PLOD3',\n",
       " 'DHX16',\n",
       " 'OR2W1',\n",
       " 'AGTR2',\n",
       " 'MTR',\n",
       " 'ALDH1A2',\n",
       " 'FGF4',\n",
       " 'CASP8',\n",
       " 'PPID',\n",
       " 'IFNG',\n",
       " 'LIPE',\n",
       " 'TREX1',\n",
       " 'OR2L8',\n",
       " 'OR5AC2',\n",
       " 'NCSTN',\n",
       " 'SEMA3F',\n",
       " 'CHEK1',\n",
       " 'CALCR',\n",
       " 'GBE1',\n",
       " 'ULBP3',\n",
       " 'NDUFA3',\n",
       " 'OR4K17',\n",
       " 'RYR3',\n",
       " 'CACNA1C',\n",
       " 'SCARB2',\n",
       " 'NPY5R',\n",
       " 'AGRP',\n",
       " 'U2AF1',\n",
       " 'CD79A',\n",
       " 'PIK3C2B',\n",
       " 'APEX1',\n",
       " 'PEX14',\n",
       " 'SYK',\n",
       " 'ENTPD5',\n",
       " 'ATP6V1H',\n",
       " 'SLC27A2',\n",
       " 'MCM5',\n",
       " 'CALM2',\n",
       " 'PF4',\n",
       " 'PHKA1',\n",
       " 'DECR2',\n",
       " 'SLC2A1',\n",
       " 'CAPN1',\n",
       " 'B4GALT6',\n",
       " 'GHSR',\n",
       " 'DUSP1',\n",
       " 'PDE6C',\n",
       " 'E2F2',\n",
       " 'PFKFB2',\n",
       " 'GNPDA2',\n",
       " 'TSC1',\n",
       " 'OR7G2',\n",
       " 'CBS',\n",
       " 'ATG3',\n",
       " 'PIP5K1C',\n",
       " 'OR52L1',\n",
       " 'CD40',\n",
       " 'RB1',\n",
       " 'IFT57',\n",
       " 'DTX3L',\n",
       " 'EDNRB',\n",
       " 'OR7A10',\n",
       " 'IL12RB2',\n",
       " 'FANCL',\n",
       " 'MCM2',\n",
       " 'ADRB2',\n",
       " 'RPS17',\n",
       " 'SLIT2',\n",
       " 'EGFR',\n",
       " 'HK3',\n",
       " 'NCF4',\n",
       " 'RELA',\n",
       " 'CDC7',\n",
       " 'OR52E4',\n",
       " 'SERPINE1',\n",
       " 'ASAP2',\n",
       " 'ZBTB17',\n",
       " 'OR2T12',\n",
       " 'DAG1',\n",
       " 'FBXW7',\n",
       " 'CA2',\n",
       " 'KIDINS220',\n",
       " 'MAPK11',\n",
       " 'CCL27',\n",
       " 'SIAH1',\n",
       " 'RNASEH1',\n",
       " 'OR6V1',\n",
       " 'TFRC',\n",
       " 'ALG9',\n",
       " 'DLL3',\n",
       " 'IFNA14',\n",
       " 'PDIA4',\n",
       " 'OR2T2',\n",
       " 'GH1',\n",
       " 'APOC3',\n",
       " 'GALNT2',\n",
       " 'ACYP1',\n",
       " 'EXT2',\n",
       " 'SELP',\n",
       " 'PARP3',\n",
       " 'ATP6V1C2',\n",
       " 'OR10AD1',\n",
       " 'AIRE',\n",
       " 'MTNR1A',\n",
       " 'ACYP2',\n",
       " 'OAT',\n",
       " 'ATM',\n",
       " 'OR8J1',\n",
       " 'FLCN',\n",
       " 'B3GNT7',\n",
       " 'DGKA',\n",
       " 'MAD2L2',\n",
       " 'PRG2',\n",
       " 'ACSM3',\n",
       " 'HHEX',\n",
       " 'POLR1B',\n",
       " 'AMHR2',\n",
       " 'ID1',\n",
       " 'IGF1R',\n",
       " 'CSNK2A1',\n",
       " 'PRPF40A',\n",
       " 'PRKCZ',\n",
       " 'ATP6V1B2',\n",
       " 'RPL35A',\n",
       " 'IGFBP3',\n",
       " 'RPL32',\n",
       " 'NT5C1A',\n",
       " 'DLG1',\n",
       " 'CCR5',\n",
       " 'XCL2',\n",
       " 'FZD3',\n",
       " 'ANAPC7',\n",
       " 'TSHB',\n",
       " 'FOXA3',\n",
       " 'AGRN',\n",
       " 'TXNDC12',\n",
       " 'MTMR6',\n",
       " 'RPS11',\n",
       " 'OR4D1',\n",
       " 'VPS37B',\n",
       " 'ME1',\n",
       " 'LNPEP',\n",
       " 'WAS',\n",
       " 'CYP2C18',\n",
       " 'BDKRB2',\n",
       " 'PITX2',\n",
       " 'MAPK13',\n",
       " 'OR9A2',\n",
       " 'RAD23B',\n",
       " 'NDUFB2',\n",
       " 'ATG12',\n",
       " 'EFNB1',\n",
       " 'CCL19',\n",
       " 'TYMP',\n",
       " 'ABCD1',\n",
       " 'CNTN1',\n",
       " 'CDK1',\n",
       " 'CD81',\n",
       " 'GSTO2',\n",
       " 'ACVRL1',\n",
       " 'SLC2A2',\n",
       " 'OR11H4',\n",
       " 'CD27',\n",
       " 'BCAR1',\n",
       " 'ISY1',\n",
       " 'INSRR',\n",
       " 'BMPR1A',\n",
       " 'PLCG2',\n",
       " 'MTNR1B',\n",
       " 'PAX8',\n",
       " 'SPRY1',\n",
       " 'OR2V2',\n",
       " 'FARSB',\n",
       " 'AGK',\n",
       " 'AP2B1',\n",
       " 'ACACA',\n",
       " 'STX12',\n",
       " 'CCL18',\n",
       " 'OR6C75',\n",
       " 'EZR',\n",
       " 'OR1C1',\n",
       " 'LIFR',\n",
       " 'ARHGEF2',\n",
       " 'ITGAE',\n",
       " 'F10',\n",
       " 'DKK4',\n",
       " 'CA6',\n",
       " 'ENPP7',\n",
       " 'TAS2R41',\n",
       " 'IDI1',\n",
       " 'WNT10B',\n",
       " 'MMP2',\n",
       " 'TPMT',\n",
       " 'PDE10A',\n",
       " 'CALM1',\n",
       " 'SHC4',\n",
       " 'POLA1',\n",
       " 'TAOK1',\n",
       " 'AASS',\n",
       " 'LGMN',\n",
       " 'AGL',\n",
       " 'SGCA',\n",
       " 'IRF7',\n",
       " 'TGFB2',\n",
       " 'VTI1B',\n",
       " 'IFNA7',\n",
       " 'STX8',\n",
       " 'OR52B6',\n",
       " 'CFL1',\n",
       " 'PIGU',\n",
       " 'SF3B1',\n",
       " 'ANAPC11',\n",
       " 'IL17RA',\n",
       " 'COX7A2',\n",
       " 'ADORA1',\n",
       " 'OR10K1',\n",
       " 'CRY1',\n",
       " 'TAF5L',\n",
       " 'UPRT',\n",
       " 'MCHR1',\n",
       " 'UBE3B',\n",
       " 'AMPD3',\n",
       " 'OR52N4',\n",
       " 'RPL7',\n",
       " 'PROC',\n",
       " 'SF3B5',\n",
       " 'PLG',\n",
       " 'JUN',\n",
       " 'PPP3R1',\n",
       " 'SEPSECS',\n",
       " 'SFRP5',\n",
       " 'PLCB4',\n",
       " 'TNFSF4',\n",
       " 'MGAT4A',\n",
       " 'OR51F1',\n",
       " 'PTPRN2',\n",
       " 'STS',\n",
       " 'SOCS2',\n",
       " 'WASF1',\n",
       " 'LTA',\n",
       " 'BMP7',\n",
       " 'PDGFRB',\n",
       " 'OR7A5',\n",
       " 'CASK',\n",
       " 'HIBCH',\n",
       " 'TLR8',\n",
       " 'HYAL1',\n",
       " 'FH',\n",
       " 'CACNA1B',\n",
       " 'FRS2',\n",
       " 'GABRQ',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View all gene names\n",
    "xx = df_train.drop(columns=['event2','T2','event1','T1'])\n",
    "xx.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MGST2</th>\n",
       "      <th>SGK1</th>\n",
       "      <th>PARD6B</th>\n",
       "      <th>DRD3</th>\n",
       "      <th>GNG10</th>\n",
       "      <th>TAAR2</th>\n",
       "      <th>FZR1</th>\n",
       "      <th>CNTFR</th>\n",
       "      <th>E2F5</th>\n",
       "      <th>IFNA1</th>\n",
       "      <th>...</th>\n",
       "      <th>SMC1B</th>\n",
       "      <th>IL1B</th>\n",
       "      <th>L2HGDH</th>\n",
       "      <th>PPARGC1A</th>\n",
       "      <th>VCAM1</th>\n",
       "      <th>MADCAM1</th>\n",
       "      <th>event2</th>\n",
       "      <th>T2</th>\n",
       "      <th>event1</th>\n",
       "      <th>T1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.64</td>\n",
       "      <td>8.29</td>\n",
       "      <td>8.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.76</td>\n",
       "      <td>2.36</td>\n",
       "      <td>6.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.76</td>\n",
       "      <td>5.43</td>\n",
       "      <td>8.17</td>\n",
       "      <td>2.04</td>\n",
       "      <td>8.43</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0</td>\n",
       "      <td>4047</td>\n",
       "      <td>1</td>\n",
       "      <td>1808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.36</td>\n",
       "      <td>9.24</td>\n",
       "      <td>8.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.87</td>\n",
       "      <td>4.16</td>\n",
       "      <td>6.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.42</td>\n",
       "      <td>4.64</td>\n",
       "      <td>8.19</td>\n",
       "      <td>2.09</td>\n",
       "      <td>9.61</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0</td>\n",
       "      <td>4005</td>\n",
       "      <td>0</td>\n",
       "      <td>4005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.89</td>\n",
       "      <td>9.58</td>\n",
       "      <td>7.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.74</td>\n",
       "      <td>5.18</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>3.20</td>\n",
       "      <td>8.03</td>\n",
       "      <td>2.47</td>\n",
       "      <td>9.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1474</td>\n",
       "      <td>0</td>\n",
       "      <td>1474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.35</td>\n",
       "      <td>9.57</td>\n",
       "      <td>10.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.35</td>\n",
       "      <td>3.01</td>\n",
       "      <td>7.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.02</td>\n",
       "      <td>6.36</td>\n",
       "      <td>7.33</td>\n",
       "      <td>3.60</td>\n",
       "      <td>8.64</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1477</td>\n",
       "      <td>0</td>\n",
       "      <td>1477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.44</td>\n",
       "      <td>7.42</td>\n",
       "      <td>9.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.36</td>\n",
       "      <td>3.58</td>\n",
       "      <td>8.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.42</td>\n",
       "      <td>8.38</td>\n",
       "      <td>4.76</td>\n",
       "      <td>4.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>8.98</td>\n",
       "      <td>9.25</td>\n",
       "      <td>9.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.39</td>\n",
       "      <td>5.08</td>\n",
       "      <td>7.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.56</td>\n",
       "      <td>4.29</td>\n",
       "      <td>6.97</td>\n",
       "      <td>4.25</td>\n",
       "      <td>6.58</td>\n",
       "      <td>2.84</td>\n",
       "      <td>0</td>\n",
       "      <td>347</td>\n",
       "      <td>0</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>8.86</td>\n",
       "      <td>10.93</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.12</td>\n",
       "      <td>8.63</td>\n",
       "      <td>7.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>5.80</td>\n",
       "      <td>7.69</td>\n",
       "      <td>4.99</td>\n",
       "      <td>10.37</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0</td>\n",
       "      <td>467</td>\n",
       "      <td>0</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>9.46</td>\n",
       "      <td>11.30</td>\n",
       "      <td>6.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.81</td>\n",
       "      <td>7.98</td>\n",
       "      <td>7.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.59</td>\n",
       "      <td>7.37</td>\n",
       "      <td>6.34</td>\n",
       "      <td>9.90</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0</td>\n",
       "      <td>488</td>\n",
       "      <td>0</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>10.33</td>\n",
       "      <td>10.89</td>\n",
       "      <td>7.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.22</td>\n",
       "      <td>2.37</td>\n",
       "      <td>6.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.03</td>\n",
       "      <td>6.69</td>\n",
       "      <td>6.32</td>\n",
       "      <td>4.95</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0</td>\n",
       "      <td>3287</td>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>9.19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>10.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.75</td>\n",
       "      <td>2.47</td>\n",
       "      <td>7.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.17</td>\n",
       "      <td>5.19</td>\n",
       "      <td>8.69</td>\n",
       "      <td>2.72</td>\n",
       "      <td>7.91</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0</td>\n",
       "      <td>3256</td>\n",
       "      <td>0</td>\n",
       "      <td>3256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>692 rows × 4917 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MGST2   SGK1  PARD6B  DRD3  GNG10  TAAR2   FZR1  CNTFR  E2F5  IFNA1  \\\n",
       "0      8.64   8.29    8.74  0.00   8.01    0.0  10.76   2.36  6.99    0.0   \n",
       "1      9.36   9.24    8.23  0.00   8.57    0.0  10.87   4.16  6.45    0.0   \n",
       "2      9.89   9.58    7.82  0.00   9.13    0.0  10.74   5.18  7.50    0.0   \n",
       "5      9.35   9.57   10.09  0.00   8.40    0.0  10.35   3.01  7.36    0.0   \n",
       "7      9.44   7.42    9.47  0.00   9.01    0.0  10.36   3.58  8.04    0.0   \n",
       "...     ...    ...     ...   ...    ...    ...    ...    ...   ...    ...   \n",
       "1074   8.98   9.25    9.93  0.00   8.54    0.0  10.39   5.08  7.03    0.0   \n",
       "1077   8.86  10.93    8.50  0.48   9.27    0.0  10.12   8.63  7.29    0.0   \n",
       "1078   9.46  11.30    6.85  0.00   8.80    0.0   9.81   7.98  7.20    0.0   \n",
       "1079  10.33  10.89    7.64  0.00   9.51    0.0  10.22   2.37  6.68    0.0   \n",
       "1080   9.19   8.93   10.63  0.00   9.24    0.0  10.75   2.47  7.91    0.0   \n",
       "\n",
       "      ...  SMC1B  IL1B  L2HGDH  PPARGC1A  VCAM1  MADCAM1  event2    T2  \\\n",
       "0     ...   0.76  5.43    8.17      2.04   8.43     3.37       0  4047   \n",
       "1     ...   7.42  4.64    8.19      2.09   9.61     3.36       0  4005   \n",
       "2     ...   0.93  3.20    8.03      2.47   9.01     0.00       0  1474   \n",
       "5     ...   4.02  6.36    7.33      3.60   8.64     1.46       0  1477   \n",
       "7     ...   0.00  5.42    8.38      4.76   4.11     0.00       0   303   \n",
       "...   ...    ...   ...     ...       ...    ...      ...     ...   ...   \n",
       "1074  ...   0.56  4.29    6.97      4.25   6.58     2.84       0   347   \n",
       "1077  ...   0.48  5.80    7.69      4.99  10.37     2.52       0   467   \n",
       "1078  ...   4.90  4.59    7.37      6.34   9.90     2.11       0   488   \n",
       "1079  ...   3.03  6.69    6.32      4.95   9.04     0.68       0  3287   \n",
       "1080  ...   4.17  5.19    8.69      2.72   7.91     0.76       0  3256   \n",
       "\n",
       "      event1    T1  \n",
       "0          1  1808  \n",
       "1          0  4005  \n",
       "2          0  1474  \n",
       "5          0  1477  \n",
       "7          0   303  \n",
       "...      ...   ...  \n",
       "1074       0   347  \n",
       "1077       0   467  \n",
       "1078       0   488  \n",
       "1079       1   181  \n",
       "1080       0  3256  \n",
       "\n",
       "[692 rows x 4917 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/test/validation split\n",
    "df_test = df_train.sample(frac=0.2)\n",
    "df_train = df_train.drop(df_test.index)\n",
    "df_val = df_train.sample(frac=0.2)\n",
    "df_train = df_train.drop(df_val.index)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariate preprocessing\n",
    "cols_standardize =  xx.columns.tolist()\n",
    "\n",
    "standardize = [([col], StandardScaler()) for col in cols_standardize]\n",
    "\n",
    "x_mapper = DataFrameMapper(standardize)\n",
    "\n",
    "x_train = x_mapper.fit_transform(df_train).astype('float32')\n",
    "x_val = x_mapper.transform(df_val).astype('float32')\n",
    "x_test = x_mapper.transform(df_test).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretization of survival times\n",
    "class LabTransform(LabTransDiscreteTime):\n",
    "    def transform(self, durations, events):\n",
    "        durations, is_event = super().transform(durations, events > 0)\n",
    "        events[is_event == 0] = 0\n",
    "        return durations, events.astype('int64')\n",
    "        \n",
    "num_durations = 10\n",
    "\n",
    "labtrans1 = LabTransform(num_durations, scheme='equidistant')\n",
    "get_target1 = lambda df: (df['T1'].values, df['event1'].values)\n",
    "\n",
    "T1_train = labtrans1.fit_transform(*get_target1(df_train))\n",
    "T1_val = labtrans1.transform(*get_target1(df_val))\n",
    "T1_test, event1_test = labtrans1.transform(*get_target1(df_test))\n",
    "\n",
    "labtrans2 = LabTransform(num_durations, scheme='equidistant')\n",
    "get_target2 = lambda df: (df['T2'].values, df['event2'].values)\n",
    "\n",
    "T2_train = labtrans2.fit_transform(*get_target2(df_train))\n",
    "T2_val = labtrans2.transform(*get_target2(df_val))\n",
    "# Discretization is not required because the prediction time is already a continuous value after spline interpolation when evaluated on the test set\n",
    "T2_test, event2_test = get_target2(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package the data into the input format required by the network later\n",
    "def index_to_1d(i, j, n):\n",
    "    \"\"\"\n",
    "    Converts a 2D index (i, j) from sets T1 and T2, each with elements ranging from 1 to n, to a 1D index.\n",
    "    \"\"\"\n",
    "    return i * n + j\n",
    "\n",
    "T_train = list(T1_train)\n",
    "T1_train_list = list(T1_train)\n",
    "T2_train_list = list(T2_train)\n",
    "T_train[0] = index_to_1d(T1_train_list[0], T2_train_list[0], num_durations)\n",
    "T_train[1] = index_to_1d(T1_train_list[1], T2_train_list[1], 2)\n",
    "T_train = tuple(T_train)\n",
    "\n",
    "T_val = list(T1_val)\n",
    "T1_val_list = list(T1_val)\n",
    "T2_val_list = list(T2_val)\n",
    "T_val[0] = index_to_1d(T1_val_list[0], T2_val_list[0], num_durations)\n",
    "T_val[1] = index_to_1d(T1_val_list[1], T2_val_list[1], 2)\n",
    "T_val = tuple(T_val)\n",
    "val = (x_val, T_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network architecture\n",
    "class MaskedLinearLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True, mask=None):\n",
    "        super(MaskedLinearLayer, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if bias:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "        self.mask = mask if mask is not None else torch.ones(out_features, in_features)\n",
    "\n",
    "    def forward(self, input):\n",
    "        masked_weight = self.weight * self.mask\n",
    "        return nn.functional.linear(input, masked_weight, self.bias)\n",
    "\n",
    "class Multivariate_survival(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, num_nodes_shared, num_nodes_indiv, num_T1,\n",
    "                 out_features, batch_norm=True, dropout=None, mask=None):\n",
    "        super().__init__()\n",
    "        self.first_layer = MaskedLinearLayer(in_features, num_nodes_shared[0], mask=mask)\n",
    "        self.shared_net = tt.practical.MLPVanilla(\n",
    "            num_nodes_shared[0], num_nodes_shared[1:-1], num_nodes_shared[-1],\n",
    "            batch_norm, dropout,\n",
    "        )\n",
    "        self.risk_nets = torch.nn.ModuleList()\n",
    "        for _ in range(num_T1):\n",
    "            net = tt.practical.MLPVanilla(\n",
    "                num_nodes_shared[-1], num_nodes_indiv, out_features,\n",
    "                batch_norm, dropout,\n",
    "            )\n",
    "            self.risk_nets.append(net)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.first_layer(input)\n",
    "        out = self.shared_net(out)\n",
    "        out = [net(out) for net in self.risk_nets]\n",
    "        out = torch.stack(out, dim=1)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = x_train.shape[1]\n",
    "num_nodes_shared = [num_pathways, 32, 32]\n",
    "num_nodes_indiv = [32, 32]\n",
    "num_T1 = num_durations \n",
    "out_features = len(labtrans2.cuts)\n",
    "batch_norm = True\n",
    "dropout = 0.7\n",
    "\n",
    "net = Multivariate_survival(in_features, num_nodes_shared, num_nodes_indiv, num_T1,\n",
    "                       out_features, batch_norm, dropout, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class second_multi_task(tt.Model):\n",
    "\n",
    "    def __init__(self, net, optimizer=None, device=None, alpha=0.2, sigma=0.1, duration_index=None, loss=None):\n",
    "        self.duration_index = duration_index\n",
    "        if loss is None:\n",
    "            loss = Loss1(alpha, sigma)\n",
    "        super().__init__(net, loss, optimizer, device)\n",
    "\n",
    "    @property\n",
    "    def duration_index(self):\n",
    "        \n",
    "        return self._duration_index\n",
    "\n",
    "    @duration_index.setter\n",
    "    def duration_index(self, val):\n",
    "        self._duration_index = val\n",
    "\n",
    "    def make_dataloader(self, data, batch_size, shuffle, num_workers=0):\n",
    "        dataloader = super().make_dataloader(data, batch_size, shuffle, num_workers,\n",
    "                                             make_dataset=models.data.DeepHitDataset)\n",
    "        return dataloader\n",
    "    \n",
    "    def make_dataloader_predict(self, input, batch_size, shuffle=False, num_workers=0):\n",
    "        dataloader = super().make_dataloader(input, batch_size, shuffle, num_workers)\n",
    "        return dataloader\n",
    "\n",
    "    def predict_surv_df(self, input, batch_size=8224, eval_=True, num_workers=0):\n",
    "\n",
    "        surv = self.predict_pmf_1_cif_2(input, batch_size, True, eval_, True, num_workers)\n",
    "        return pd.DataFrame(surv, self.duration_index)\n",
    "\n",
    "    def predict_surv_2_condpmf_1(self, input, batch_size=8224, numpy=None, eval_=True,\n",
    "                     to_cpu=False, num_workers=0):\n",
    " \n",
    "        cif = self.predict_pmf_1_cif_2(input, batch_size, False, eval_, to_cpu, num_workers)\n",
    "        pmf = self.predict_pmf_1(input, batch_size, False, eval_, to_cpu, num_workers)\n",
    "        condsurv = 1. - cif/pmf\n",
    "        return tt.utils.array_or_tensor(condsurv, numpy, input)\n",
    "        \n",
    "    def predict_pmf_1_cif_2(self, input, batch_size=8224, numpy=None, eval_=True,\n",
    "                     to_cpu=False, num_workers=0):\n",
    " \n",
    "        pmf = self.predict_pmf_12(input, batch_size, False, eval_, to_cpu, num_workers)\n",
    "        cif = pmf.cumsum(1)\n",
    "        return tt.utils.array_or_tensor(cif, numpy, input) \n",
    "\n",
    "    def predict_pmf_1(self, input, batch_size=8224, numpy=None, eval_=True,\n",
    "                     to_cpu=False, num_workers=0):\n",
    " \n",
    "        pmf12 = self.predict_pmf_12(input, batch_size, False, eval_, to_cpu, num_workers)\n",
    "        pmf = pmf12.sum(1)\n",
    "        return tt.utils.array_or_tensor(pmf, numpy, input)\n",
    "    \n",
    "    def predict_pmf_12(self, input, batch_size=8224, numpy=None, eval_=True,\n",
    "                     to_cpu=False, num_workers=0):\n",
    " \n",
    "        preds = self.predict(input, batch_size, False, eval_, False, to_cpu, num_workers)\n",
    "        pmf = pad_col(preds.view(preds.size(0), -1)).softmax(1)[:, :-1]\n",
    "        pmf = pmf.view(preds.shape).transpose(0, 1).transpose(1, 2)\n",
    "        return tt.utils.array_or_tensor(pmf, numpy, input)\n",
    "\n",
    "def _reduction(loss: Tensor, reduction: str = 'mean') -> Tensor:\n",
    "    if reduction == 'none':\n",
    "        return loss\n",
    "    elif reduction == 'mean':\n",
    "        return loss.mean()\n",
    "    elif reduction == 'sum':\n",
    "        return loss.sum()\n",
    "    raise ValueError(f\"`reduction` = {reduction} is not valid. Use 'none', 'mean' or 'sum'.\")\n",
    "\n",
    "def _diff_cdf_at_time_i(pmf: Tensor, y: Tensor) -> Tensor:\n",
    "\n",
    "    n = pmf.shape[0]\n",
    "    ones = torch.ones((n, 1), device=pmf.device)\n",
    "    r = pmf.cumsum(1).matmul(y.transpose(0, 1))\n",
    "    diag_r = r.diag().view(1, -1)\n",
    "    r = ones.matmul(diag_r) - r\n",
    "    return r.transpose(0, 1)\n",
    "\n",
    "def _rank_loss_deephit(pmf: Tensor, y: Tensor, rank_mat: Tensor, sigma: float,\n",
    "                       reduction: str = 'mean') -> Tensor:\n",
    "\n",
    "    r = _diff_cdf_at_time_i(pmf, y)\n",
    "    loss = rank_mat * torch.exp(-r/sigma)\n",
    "    loss = loss.mean(1, keepdim=True)\n",
    "    return _reduction(loss, reduction)\n",
    "\n",
    "def index_from_1d(k, n):\n",
    "\n",
    "    i = k // n\n",
    "    j = k % n\n",
    "    return (i, j)\n",
    "    \n",
    "def nll_pmf_cr(phi: Tensor, idx_durations: Tensor, events: Tensor, reduction: str = 'mean',\n",
    "               epsilon: float = 1e-7) -> Tensor:\n",
    "\n",
    "    events = events.view(-1)\n",
    "    event_00 = (events == 0).float()\n",
    "    event_01 = (events == 1).float()\n",
    "    event_02 = (events == 2).float()\n",
    "    event_03 = (events == 3).float()\n",
    "    \n",
    "    idx_durations1, idx_durations2 = index_from_1d(idx_durations.view(-1), num_durations)\n",
    "    batch_size = phi.size(0)\n",
    "    sm = utils.pad_col(phi.view(batch_size, -1)).softmax(1)[:, :-1].view(phi.shape)\n",
    "    index = torch.arange(batch_size)\n",
    "    part1 = sm[index, idx_durations1, idx_durations2].relu().add(epsilon).log().mul(event_03)\n",
    "    part2 = (sm[index, idx_durations1, :].sum(1) - sm.cumsum(2)[index, idx_durations1, idx_durations2]).relu().add(epsilon).log().mul(event_02)\n",
    "    part3 = (sm[index, :, idx_durations2].sum(1) - sm.cumsum(1)[index, idx_durations1, idx_durations2]).relu().add(epsilon).log().mul(event_01)\n",
    "    part4 = (1 - sm.cumsum(2)[index, :, idx_durations2].sum(1) + sm.cumsum(1).cumsum(2)[index, idx_durations1, idx_durations2] - sm.cumsum(1)[index, idx_durations1, :].sum(1)).relu().add(epsilon).log().mul(event_00)     \n",
    "     \n",
    "    loss = - part1.add(part2).add(part3).add(part4)\n",
    "    return _reduction(loss, reduction)\n",
    "\n",
    "\n",
    "\n",
    "def rank_loss_deephit_cr(phi: Tensor, idx_durations: Tensor, events: Tensor, rank_mat: Tensor,\n",
    "                         sigma: float, reduction: str = 'mean') -> Tensor:\n",
    "\n",
    "    idx_durations = idx_durations.view(-1)\n",
    "    events = events.view(-1)\n",
    "    event_00 = (events == 0).float()\n",
    "    event_01 = (events == 1).float()\n",
    "    event_02 = (events == 2).float()\n",
    "    event_03 = (events == 3).float()\n",
    "\n",
    "    batch_size = phi.size(0)\n",
    "    pmf = utils.pad_col(phi.view(batch_size, -1)).softmax(1)[:, :-1].view(phi.shape)\n",
    "    y = torch.zeros_like(pmf)\n",
    "    y[torch.arange(batch_size), :, idx_durations] = 1.\n",
    "\n",
    "    loss = []\n",
    "    for i in range(4):\n",
    "        rank_loss_i = _rank_loss_deephit(pmf[:, i, :], y[:, i, :], rank_mat, sigma, 'none')\n",
    "        loss.append(rank_loss_i.view(-1) * (events == i).float())\n",
    "\n",
    "    if reduction == 'none':\n",
    "        return sum(loss)\n",
    "    elif reduction == 'mean':\n",
    "        return sum([lo.mean() for lo in loss])\n",
    "    elif reduction == 'sum':\n",
    "        return sum([lo.sum() for lo in loss])\n",
    "    return _reduction(loss, reduction)\n",
    "\n",
    "class _Loss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, reduction: str = 'mean') -> None:\n",
    "        super().__init__()\n",
    "        self.reduction = reduction\n",
    "\n",
    "class _Loss1(_Loss):\n",
    "\n",
    "    def __init__(self, alpha: float, sigma: float, reduction: str = 'mean') -> None:\n",
    "        super().__init__(reduction)\n",
    "        self.alpha = alpha\n",
    "        self.sigma = sigma\n",
    "\n",
    "    @property\n",
    "    def alpha(self) -> float:\n",
    "        return self._alpha\n",
    "\n",
    "    @alpha.setter\n",
    "    def alpha(self, alpha: float) -> None:\n",
    "        if (alpha < 0) or (alpha > 1):\n",
    "            raise ValueError(f\"Need `alpha` to be in [0, 1]. Got {alpha}.\")\n",
    "        self._alpha = alpha\n",
    "\n",
    "    @property\n",
    "    def sigma(self) -> float:\n",
    "        return self._sigma\n",
    "\n",
    "    @sigma.setter\n",
    "    def sigma(self, sigma: float) -> None:\n",
    "        if sigma <= 0:\n",
    "            raise ValueError(f\"Need `sigma` to be positive. Got {sigma}.\")\n",
    "        self._sigma = sigma\n",
    "\n",
    "class Loss1(_Loss1):\n",
    "\n",
    "    def forward(self, phi: Tensor, idx_durations: Tensor, events: Tensor, rank_mat: Tensor) -> Tensor:\n",
    "        nll =  nll_pmf_cr(phi, idx_durations, events, self.reduction)\n",
    "        return nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linbo/anaconda3/envs/pycox/lib/python3.8/site-packages/torchtuples/callbacks.py:607: UserWarning: This overload of add is deprecated:\n",
      "\tadd(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd(Tensor other, *, Number alpha) (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1630.)\n",
      "  p.data = p.data.add(-weight_decay * eta, p.data)\n"
     ]
    }
   ],
   "source": [
    "optimizer = tt.optim.AdamWR(lr=0.8, decoupled_weight_decay=0.01,\n",
    "                                    cycle_eta_multiplier=0.9)\n",
    "model = second_multi_task(net, optimizer, alpha=1,\n",
    "                   duration_index=labtrans1.cuts)\n",
    "batch_size = 128\n",
    "lrfind = model.lr_finder(x_train, T_train, batch_size, tolerance=50)\n",
    "model.optimizer.set_lr(lrfind.get_best_lr()) # The learning rates for the AdamWR optimizer were adjusted using the method proposed by Smith\n",
    "epochs = 512\n",
    "callbacks = [tt.callbacks.EarlyStoppingCycle()]\n",
    "verbose = False\n",
    "log = model.fit(x_train, T_train, batch_size, epochs, callbacks, verbose, val_data=val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-index: 0.8702086189011654\n",
      "IBS: 0.09567708604324636\n"
     ]
    }
   ],
   "source": [
    "# Spline interpolation and evaluation of predictive performance\n",
    "index = torch.arange(T1_test.size)\n",
    "x = np.linspace(0, num_durations-1, num_durations)\n",
    "\n",
    "xnew = np.linspace(0, num_durations-1, 10000)\n",
    "ynew=[]    \n",
    "for i in range(T2_test[event1_test==1].size):  \n",
    "    spline_interp = UnivariateSpline(x, (1. - (model.predict_pmf_12(x_test)[T1_test[event1_test==1],:,index[event1_test==1]].T\n",
    "                                               /model.predict_pmf_12(x_test)[T1_test[event1_test==1],:,index[event1_test==1]].sum(1)).cumsum(0))[:,i], s=0)\n",
    "    y_spline = spline_interp(xnew)\n",
    "    ynew.append(y_spline)\n",
    "        \n",
    "ynew_array = np.stack(ynew, axis=1)\n",
    "    \n",
    "surv1 = pd.DataFrame(ynew_array, np.linspace(0, labtrans2.cuts.max(), 10000))\n",
    "    \n",
    "ev1 = EvalSurv(surv1, np.array(T2_test[event1_test==1]), np.array(event2_test)[event1_test==1], censor_surv='km')\n",
    "\n",
    "ynew=[]\n",
    "\n",
    "for i in range(T2_test[event1_test==0].size):  \n",
    "    spline_interp = UnivariateSpline(x, (1-((model.predict_pmf_12(x_test).sum(0)[:,event1_test==0]-model.predict_pmf_12(x_test).cumsum(0)[T1_test[event1_test==0],:,index[event1_test==0]].T)\n",
    "                                            /(1-model.predict_pmf_12(x_test).cumsum(0)[T1_test[event1_test==0],:,index[event1_test==0]].sum(1))).cumsum(0))[:,i], s=0)\n",
    "    y_spline = spline_interp(xnew)\n",
    "    ynew.append(y_spline)\n",
    "\n",
    "ynew_array = np.stack(ynew, axis=1)\n",
    "    \n",
    "surv2 = pd.DataFrame(ynew_array, np.linspace(0, labtrans2.cuts.max(), 10000))\n",
    "\n",
    "ev2 = EvalSurv(surv2, np.array(T2_test[event1_test==0]), np.array(event2_test)[event1_test==0], censor_surv='km')\n",
    "\n",
    "time_grid = np.linspace(T2_test.min(), T2_test.max(), 100) \n",
    "\n",
    "C_index=(ev1.concordance_td()*T2_test[event1_test==1].size + ev2.concordance_td()*T2_test[event1_test==0].size)/T2_test.size\n",
    "\n",
    "IBS=(ev1.integrated_brier_score(time_grid)*T2_test[event1_test==1].size + ev2.integrated_brier_score(time_grid)*T2_test[event1_test==0].size)/T2_test.size\n",
    "\n",
    "print(\"C-index:\", C_index)\n",
    "print(\"IBS:\", IBS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
